# EU AI Act - Requirements for High-Risk AI Systems
# This file should contain the full text of Articles 8-15, 26-27, and 50
# Target: ~25,000 tokens

# TODO: Add full text from official EU AI Act for the following articles:

# ARTICLE 8 - Compliance with requirements
# ARTICLE 9 - Risk management system
# ARTICLE 10 - Data and data governance
# ARTICLE 11 - Technical documentation
# ARTICLE 12 - Record-keeping
# ARTICLE 13 - Transparency and provision of information to deployers
# ARTICLE 14 - Human oversight
# ARTICLE 15 - Accuracy, robustness and cybersecurity

# ARTICLE 26 - Obligations of deployers of high-risk AI systems
# ARTICLE 27 - Fundamental rights impact assessment for high-risk AI systems

# ARTICLE 50 - Transparency obligations for providers and deployers of certain AI systems

# PLACEHOLDER CONTENT FOR DEVELOPMENT
# This is a simplified version for testing purposes

ARTICLE 9 - RISK MANAGEMENT SYSTEM:
Providers of high-risk AI systems shall establish, implement, document and maintain a risk management system consisting of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system. The risk management system shall:
- Identify and analyze known and foreseeable risks
- Estimate and evaluate risks that may emerge when the system is used as intended
- Evaluate risks based on data gathered from post-market monitoring
- Adopt suitable risk management measures

ARTICLE 10 - DATA AND DATA GOVERNANCE:
High-risk AI systems shall be developed using training, validation and testing data sets that meet quality criteria:
- Training, validation and testing data sets shall be relevant, representative, free of errors and complete
- Data sets shall have appropriate statistical properties
- Data sets shall take into account characteristics or elements particular to the specific geographical, behavioral or functional setting
- To the extent required, data sets shall be subject to appropriate data governance and management practices

ARTICLE 11 - TECHNICAL DOCUMENTATION:
The technical documentation shall be drawn up before the system is placed on the market or put into service and kept up to date. The documentation shall:
- Provide a general description of the AI system
- Describe the system architecture and design
- Document the development process and design choices
- Detail the data requirements and how they are met
- Describe the testing procedures and results
- Include the risk management documentation

ARTICLE 12 - RECORD-KEEPING:
High-risk AI systems shall be designed with capabilities enabling automatic recording of events while the systems are operating. The logging capabilities shall:
- Record events relevant to identifying risks and relevant circumstances
- Enable post-market monitoring
- Facilitate investigations of incidents or anomalies
- Ensure appropriate level of traceability

ARTICLE 13 - TRANSPARENCY AND PROVISION OF INFORMATION:
Providers shall ensure that high-risk AI systems are designed and developed with capabilities enabling deployers to:
- Understand how the AI system functions
- Interpret the system's output
- Use the system appropriately
- Monitor the system's operation
- Identify and address anomalies, dysfunctions and unexpected performance

ARTICLE 14 - HUMAN OVERSIGHT:
High-risk AI systems shall be designed and developed with human oversight measures, including:
- Human-machine interface that is appropriate to the circumstances
- Ensuring that natural persons can fully understand the capacities and limitations of the system
- Enabling humans to be aware of automation bias
- Enabling humans to correctly interpret the output
- Enabling humans to decide not to use the system or to override its output

ARTICLE 15 - ACCURACY, ROBUSTNESS AND CYBERSECURITY:
High-risk AI systems shall be designed and developed to achieve appropriate levels of:
- Accuracy: The system should achieve its intended purpose with minimal errors
- Robustness: The system should perform consistently across different conditions
- Cybersecurity: The system should be resilient against attempts to alter its use or performance

ARTICLE 26 - OBLIGATIONS OF DEPLOYERS:
Deployers of high-risk AI systems shall:
- Take appropriate technical and organizational measures to use the system in accordance with instructions
- Assign human oversight to competent persons
- Monitor the operation based on instructions of use
- Keep logs automatically generated by the system
- Inform the provider and distributor of any serious incident or malfunctioning
- Conduct a fundamental rights impact assessment

ARTICLE 27 - FUNDAMENTAL RIGHTS IMPACT ASSESSMENT:
Prior to deploying a high-risk AI system, deployers shall perform an assessment of its impact on fundamental rights. The assessment shall include:
- Description of the deployer's processes for using the system
- Categories of natural persons and groups likely to be affected
- Specific risks of harm identified
- Measures to address and mitigate those risks
- Whether a data protection impact assessment has been undertaken

ARTICLE 50 - TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS:
Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that:
- Natural persons are informed they are interacting with an AI system
- AI-generated content is marked in a machine-readable format and detectable as artificially generated
- Deep fakes are appropriately labeled
